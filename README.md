# A2J: Anchor-to-Joint Regression Network for 3D Articulated Pose Estimation from a Single Depth Image
## Introduction
This is the official implementation for the paper, **"A2J: Anchor-to-Joint Regression Network for 3D Articulated Pose Estimation from a Single Depth Image"**, ICCV 2019. 

In this paper, we propose a simple and effective approach termed A2J, for 3D hand and human pose estimation from a single depth image. Wide-range evaluations on 5 datasets demonstrate A2J's superiority.

Please refer to our paper for more details, https://arxiv.org/abs/1908.09999.

![pipeline](https://github.com/zhangboshen/A2J/blob/master/fig/A2Jpipeline.png)

If you find our work useful in your research or publication, please cite our work:
```
@inproceedings{A2J,
author = {Xiong, Fu and Zhang, Boshen and Xiao, Yang and Cao, Zhiguo and Yu, Taidong and Zhou Tianyi, Joey and Yuan, Junsong},
title = {A2J: Anchor-to-Joint Regression Network for 3D Articulated Pose Estimation from a Single Depth Image},
booktitle = {Proceedings of the IEEE Conference on International Conference on Computer Vision (ICCV)},
year = {2019}
}
```

## Qualitative Results
#### [NYU](https://jonathantompson.github.io/NYU_Hand_Pose_Dataset.htm) hand pose dataset:
![NYU_1](https://github.com/zhangboshen/A2J/blob/master/fig/NYU_1.png)
&nbsp;

#### [ITOP](https://www.alberthaque.com/projects/viewpoint_3d_pose/) body pose dataset:
![ITOP_1](https://github.com/zhangboshen/A2J/blob/master/fig/ITOP_1.png)


# Code is coming soon...


